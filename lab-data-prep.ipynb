{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asr/tensorflow-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/asr/tensorflow-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPORA: Specific vs Generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus_cal_1: 99412, Corpus_cal_2: 266442, Corpus_2: 10111563, Ratio: 0.036\n",
      "CPU times: user 4.93 s, sys: 2.08 s, total: 7.01 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NOTE: Put in corpus_2 the largest corpus\n",
    "\n",
    "num_lines_corpus_spec_1  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/calendar/jsgf/jsgf-calendar-1'))\n",
    "num_lines_corpus_spec_2  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/calendar/subtitles/subtitle-cleaned-keyfiltered'))\n",
    "#num_lines_corpus_2  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/generic/paisa-cleaned-v8-0'))\n",
    "num_lines_corpus_gen_2  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/generic-maxlength16/generic-corpus-maxlength16-v1'))\n",
    "\n",
    "ratio_cal = num_lines_corpus_spec_1 / float(num_lines_corpus_spec_2)\n",
    "ratio = (num_lines_corpus_spec_1 + num_lines_corpus_spec_2) / float(num_lines_corpus_gen_2) #if num_lines_corpus_1 < num_lines_corpus_1 else num_lines_corpus_2 / float(num_lines_corpus_1)\n",
    "print('Corpus_cal_1: %d, Corpus_cal_2: %d, Corpus_2: %d, Ratio: %0.3f' %(num_lines_corpus_spec_1, num_lines_corpus_spec_2, num_lines_corpus_gen_2, ratio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37310934462284473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_cal = num_lines_corpus_spec_1 / float(num_lines_corpus_spec_2)\n",
    "ratio_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPORA: Specific_1 vs Specific_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus_1: 893346, Corpus_2: 950421, Ratio: 0.940\n",
      "CPU times: user 459 ms, sys: 50.3 ms, total: 510 ms\n",
      "Wall time: 946 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NOTE: Put in corpus_2 the largest corpus\n",
    "\n",
    "# num_lines_corpus_1  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/calendar/jsgf-calendar-1'))\n",
    "# num_lines_corpus_2  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/generic/paisa-cleaned-v8-0'))\n",
    "\n",
    "num_lines_corpus_1 = 0\n",
    "num_lines_corpus_2 = 0\n",
    "\n",
    "for num in [1,2,3]:\n",
    "    num_lines_corpus_1 += sum(1 for line in open('/home/asr/Data/classif_task/jsgf_data/email/email_' + str(num) + '.expand'))\n",
    "    num_lines_corpus_2 += sum(1 for line in open('/home/asr/Data/classif_task/jsgf_data/reminder/reminder_' + str(num) + '.expand'))\n",
    "\n",
    "\n",
    "ratio = num_lines_corpus_1 / float(num_lines_corpus_2) #if num_lines_corpus_1 < num_lines_corpus_1 else num_lines_corpus_2 / float(num_lines_corpus_1)\n",
    "print('Corpus_1: %d, Corpus_2: %d, Ratio: %0.3f' %(num_lines_corpus_1, num_lines_corpus_2, ratio)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Data-Frame (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (num_lines_corpus_cal_1 + ratio_cal*num_lines_corpus_cal_2) / float(num_lines_corpus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory_1, directory_2, directory_3):\n",
    "    # NOTE: Put in directory_2 the largest corpus\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"class\"] = []\n",
    "    l1 = 0\n",
    "    for file_path in os.listdir(directory_1):\n",
    "        with tf.gfile.GFile(os.path.join(directory_1 , file_path), \"rb\") as f:\n",
    "                # strip() removes white spaces before and after the string\n",
    "                # decode() converst a byte object ('b) in a python3 string\n",
    "                list_of_sentences = [s.strip().decode() for s in f.readlines()]\n",
    "                num_rows_1 = len(list_of_sentences)\n",
    "                for i in range(num_rows_1):\n",
    "                    data[\"sentence\"].append(list_of_sentences[i])\n",
    "                    data[\"class\"].append(1)\n",
    "    \n",
    "    for file_path in os.listdir(directory_2):\n",
    "        with tf.gfile.GFile(os.path.join(directory_2 , file_path), \"rb\") as f:\n",
    "                # strip() removes white spaces before and after the string\n",
    "                # decode() converst a byte object ('b) in a python3 string\n",
    "                list_of_sentences = [s.strip().decode() for s in f.readlines() if np.random.random() <= ratio_cal]\n",
    "                num_rows_1 = len(list_of_sentences)\n",
    "                for i in range(num_rows_1):\n",
    "                    data[\"sentence\"].append(list_of_sentences[i])\n",
    "                    data[\"class\"].append(1)\n",
    "    \n",
    "    for file_path in os.listdir(directory_3):\n",
    "        with tf.gfile.GFile(os.path.join(directory_3, file_path), \"rb\") as f:\n",
    "            # Balancing the dataset\n",
    "            list_of_sentences = [s.strip().decode() for s in f.readlines() if np.random.random() <= ratio]\n",
    "            for i in range(len(list_of_sentences)):\n",
    "                data[\"sentence\"].append(list_of_sentences[i])\n",
    "                data[\"class\"].append(0)\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.6 s, sys: 2.46 s, total: 37.1 s\n",
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "directory_1 = '/home/asr/Data/classif_task/dev_data/calendar/jsgf/'\n",
    "directory_2 = '/home/asr/Data/classif_task/dev_data/calendar/subtitles/'\n",
    "directory_3 = '/home/asr/Data/classif_task/dev_data/generic-maxlength16/'\n",
    "\n",
    "#directory_1 = '/home/asr/Data/classif_task/jsgf_data/email/'\n",
    "#directory_2 = '/home/asr/Data/classif_task/jsgf_data/reminder/'\n",
    "\n",
    "dataset_df = load_dataset(directory_1, directory_2, directory_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence\n",
       "class          \n",
       "0        366146\n",
       "1        198790"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Balanced\n",
    "dataset_df.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modifica attivit√†\n",
      "hanno mantenuto stabili al 5 per cento le loro quote sul mercato mondiale\n",
      "fai partire calendario\n",
      "venale e simoniaco alle concessioni del pontefice per cui i poveri erano spietatamente esclusi mentre i\n",
      "mostrami la vista giorno nel calendario\n",
      "protestanti che alterarono abilmente la fraseologia e le cifre di modo da fornire un aspetto esclusivamente\n",
      "vorrei aprire calendario e visualizza settimana\n",
      "ovvero comportarsi in modo diverso\n",
      "mostra applicazione agenda per favore e visualizza settimana\n",
      "di almeno quattro f15 con il lancio di ben otto aim7m che ebbero cos√¨ una notevole\n",
      "vorrei vedere la vista giorno nell'applicazione calendario per piacere\n",
      "conobbe il suo maggior splendore bastano i numeri a descriverlo 8 campionati spagnoli 5 coppe dei\n",
      "puoi aprire vista settimana nell'app calendario per favore ?\n",
      "ma dwyane wade ebbe una delle sue migliori stagioni in carriera segnando pi√π dipunti e distribuendo\n",
      "imposta notifiche nelle impostazioni dell'agenda\n",
      "ma dura poco infatti con larrivo del sole le coperture slick di scheckter gli consentono un\n",
      "vorrei vedere visualizzazione giorno nell'app calendario per piacere\n",
      "muore tra le braccia della madre carla perch√© il camion si √® ribaltato\n",
      "puoi mostrare la vista anno nell'agenda per piacere ?\n",
      "render√† conto che la scienza √® un bene o un male a seconda dell'uso che se\n"
     ]
    }
   ],
   "source": [
    "# Print some samples\n",
    "for i in range(10):\n",
    "    print(dataset_df.iloc[i]['sentence'])\n",
    "    print(dataset_df.iloc[-i -1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modifica attivit√†</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fai partire calendario</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostrami la vista giorno nel calendario</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vorrei aprire calendario e visualizza settimana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mostra applicazione agenda per favore e visual...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  class\n",
       "0                                  modifica attivit√†      1\n",
       "1                             fai partire calendario      1\n",
       "2            mostrami la vista giorno nel calendario      1\n",
       "3    vorrei aprire calendario e visualizza settimana      1\n",
       "4  mostra applicazione agenda per favore e visual...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564931</th>\n",
       "      <td>di almeno quattro f15 con il lancio di ben ott...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564932</th>\n",
       "      <td>ovvero comportarsi in modo diverso</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564933</th>\n",
       "      <td>protestanti che alterarono abilmente la fraseo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564934</th>\n",
       "      <td>venale e simoniaco alle concessioni del pontef...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564935</th>\n",
       "      <td>hanno mantenuto stabili al 5 per cento le loro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence  class\n",
       "564931  di almeno quattro f15 con il lancio di ben ott...      0\n",
       "564932                 ovvero comportarsi in modo diverso      0\n",
       "564933  protestanti che alterarono abilmente la fraseo...      0\n",
       "564934  venale e simoniaco alle concessioni del pontef...      0\n",
       "564935  hanno mantenuto stabili al 5 per cento le loro...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    11.39391\n",
       "class        1.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting number of words and mean\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    26\n",
       "class        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length sentence\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    4.402611\n",
       "class       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length sentence\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of the lengths\n",
    "%matplotlib inline\n",
    "\n",
    "length_sentence = dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1)\n",
    "plt.hist(length_sentence['sentence'],bins=range(50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non avevo legami di ambiente non avevo impegni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>un nuovo episodio di grey s anatomy la settima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>casata di leonenepote</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l ho pedinato per una settimana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assegnato al file per cui il processo dispone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in maniera obiettiva sia i pareri positivi sia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sempre limitato sulla seconda e ci√≤ port√≤ ad u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diventa collaboratore e redattore della rivist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fu onorato neldel titolo di vilas professore r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gi√† trenta anni prima merenptah aveva sconfitt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  class\n",
       "0  non avevo legami di ambiente non avevo impegni...      0\n",
       "1  un nuovo episodio di grey s anatomy la settima...      1\n",
       "2                              casata di leonenepote      0\n",
       "3                    l ho pedinato per una settimana      1\n",
       "4  assegnato al file per cui il processo dispone ...      0\n",
       "5  in maniera obiettiva sia i pareri positivi sia...      0\n",
       "6  sempre limitato sulla seconda e ci√≤ port√≤ ad u...      0\n",
       "7  diventa collaboratore e redattore della rivist...      0\n",
       "8  fu onorato neldel titolo di vilas professore r...      0\n",
       "9  gi√† trenta anni prima merenptah aveva sconfitt...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index = [i for i in range(dataset_df.shape[0])]\n",
    "random.shuffle(index)\n",
    "dataset = dataset_df.set_index([index]).sort_index()\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_csv('/home/asr/Data/classif_task/dev_data/dataset_blc.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non avevo legami di ambiente non avevo impegni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>un nuovo episodio di grey s anatomy la settima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>casata di leonenepote</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l ho pedinato per una settimana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assegnato al file per cui il processo dispone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in maniera obiettiva sia i pareri positivi sia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sempre limitato sulla seconda e ci√≤ port√≤ ad u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diventa collaboratore e redattore della rivist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fu onorato neldel titolo di vilas professore r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gi√† trenta anni prima merenptah aveva sconfitt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>puoi condividere con bianca le mie attivit√† de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>puoi condividere con carmela tramite messaggio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ti piacciono i codici criptati che ti ho manda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>limperatore tuduc cedette la cocincina orienta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>odile pensava agli eventi invece che agli uomini</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>le composizioni medicinali contenenti le sosta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l isola dei cavalli selvaggi cinema 51221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>diritto dal momento in cui il diritto non si c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l antiquarium di ventimiglia √® un museo archeo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sei persone sono state prese questa settimana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  class\n",
       "0   non avevo legami di ambiente non avevo impegni...      0\n",
       "1   un nuovo episodio di grey s anatomy la settima...      1\n",
       "2                               casata di leonenepote      0\n",
       "3                     l ho pedinato per una settimana      1\n",
       "4   assegnato al file per cui il processo dispone ...      0\n",
       "5   in maniera obiettiva sia i pareri positivi sia...      0\n",
       "6   sempre limitato sulla seconda e ci√≤ port√≤ ad u...      0\n",
       "7   diventa collaboratore e redattore della rivist...      0\n",
       "8   fu onorato neldel titolo di vilas professore r...      0\n",
       "9   gi√† trenta anni prima merenptah aveva sconfitt...      0\n",
       "10  puoi condividere con bianca le mie attivit√† de...      1\n",
       "11  puoi condividere con carmela tramite messaggio...      1\n",
       "12  ti piacciono i codici criptati che ti ho manda...      1\n",
       "13  limperatore tuduc cedette la cocincina orienta...      0\n",
       "14   odile pensava agli eventi invece che agli uomini      1\n",
       "15  le composizioni medicinali contenenti le sosta...      0\n",
       "16          l isola dei cavalli selvaggi cinema 51221      0\n",
       "17  diritto dal momento in cui il diritto non si c...      0\n",
       "18  l antiquarium di ventimiglia √® un museo archeo...      0\n",
       "19      sei persone sono state prese questa settimana      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude1 = ['\\t', '\"', '?'] # list\n",
    "exclude2 = [\"'\", \"  \", \"   \", \"    \", \"     \"] # list\n",
    "\n",
    "def clean_text(text):\n",
    "    for c in exclude1:\n",
    "        text=text.replace(c,'')\n",
    "    for c in exclude2:\n",
    "        text=text.replace(c, \" \")\n",
    "    return text.lower().strip()\n",
    "\n",
    "sentence_processed = list(map(lambda text: clean_text(text), dataset['sentence'].values))\n",
    "\n",
    "dataset['sentence'] = sentence_processed\n",
    "\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vorrei aggiungere appuntamento all agenda per ogni weekend\n",
      "larmistizio di vignale\n",
      "continu√≤ fino alsalvo l interruzione della seconda guerra mondiale e fu progettata per un pubblico femminile borghese\n",
      "parte di itachi sasuke visse solo con lo scopo di vendicare la famiglia e uccidere il\n",
      "attribuzione errata\n",
      "identificare tutto il gruppo\n",
      "puoi creare un appuntamento alle cinque di mattina per favore\n",
      "solo si rifiuta ma gli dar√† la mano in segno di rispetto\n",
      "puoi creare un evento chiamato appuntamento con massimo alle sette e quarantacinque ogni primo weekend del mese\n",
      "cioe un vero appuntamento che non fosse con un paziente o suo figlio\n",
      "variabili superando talora anche i 300 metri\n",
      "a poppa due tramogge per bombe torpedini da getto da 50 e 100 kg e due\n",
      "poi piu tardi se ne andra e rimarremo solo io e te per l evento principale\n",
      "grandi edifici il museo de logro≈ào con collezioni di sculture e quadri di varie epoche e\n",
      "la membrana della maggior parte di questi batteri grampositivi √® acido micolico con peptidoglicano il che\n",
      "cavolo stephanie e la peggiore organizzatrice di eventi della storia\n",
      "culinarie allaperto dove √® possibile assaggiare sapori e piatti della tradizione locale dinverno invece lappuntamento immancabile\n",
      "c √® una riunione d emergenza del consiglio di sicurezza a ginevra tra poche ore\n",
      "del genere umano\n",
      "gli archivi del consilgio noti come archivo general de indias sono ospitati a siviglia e dalfanno\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dataset.iloc[i]['sentence'])\n",
    "    print(dataset.iloc[-i -1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a third column with the number of words in the sentence (we count them computing the number of spaces + 1)\n",
    "\n",
    "# num_words_in_sentence = lambda x: str(x).count(' ') + 1\n",
    "\n",
    "# dataset_tmp = dataset.assign(length=dataset['sentence'])\n",
    "# dataset_tmp = dataset_tmp['length'].apply(num_words_in_sentence)\n",
    "# dataset_with_length = dataset.assign(length=dataset_tmp)\n",
    "\n",
    "# dataset_with_length.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Set size: 451948\n",
      "Validation-Set size: 112988\n"
     ]
    }
   ],
   "source": [
    "LENGTH_COLUMN = False\n",
    "\n",
    "if LENGTH_COLUMN == True:\n",
    "    dataset = dataset_with_length\n",
    "\n",
    "\n",
    "splitter =  model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=19850610)\n",
    "\n",
    "splits = list(splitter.split(X=dataset['sentence'], y=dataset['class']))\n",
    "train_index = splits[0][0]\n",
    "valid_index = splits[0][1]\n",
    "\n",
    "train_df = dataset.loc[train_index,:]\n",
    "print('Training-Set size: %d' %len(train_df))\n",
    "\n",
    "valid_df = dataset.loc[valid_index,:]\n",
    "print('Validation-Set size: %d' %len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "0    292916\n",
      "1    159032\n",
      "Name: class, dtype: int64\n",
      "class 0 %: 64.81\n",
      "class 1 %: 35.19\n",
      "\n",
      "Validation Set\n",
      "0    73230\n",
      "1    39758\n",
      "Name: class, dtype: int64\n",
      "class 0 %: 64.81\n",
      "class 1 %: 35.19\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set\")\n",
    "training_value_counts = train_df['class'].value_counts()\n",
    "print(training_value_counts)\n",
    "print(\"class 0 %: {}\".format(round(training_value_counts[0]/len(train_df)*100,2)))\n",
    "print(\"class 1 %: {}\".format(round(training_value_counts[1]/len(train_df)*100,2)))\n",
    "print(\"\")\n",
    "print(\"Validation Set\")\n",
    "validation_value_counts = valid_df['class'].value_counts()\n",
    "print(validation_value_counts)\n",
    "print(\"class 0 %: {}\".format(round(validation_value_counts[0]/len(valid_df)*100,2)))\n",
    "print(\"class 1 %: {}\".format(round(validation_value_counts[1]/len(valid_df)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LENGTH_COLUMN == True:  \n",
    "    train_df.to_csv(os.path.join(os.getcwd(), 'data-preparation/train-data-maxlength16-subtitles.tsv'), header=False, index=False, sep='\\t')\n",
    "    valid_df.to_csv(os.path.join(os.getcwd(), 'data-preparation/valid-data-maxlength16-subtitles.tsv'), header=False, index=False, sep='\\t')\n",
    "else: \n",
    "    train_df.to_csv(os.path.join(os.getcwd(), 'data-preparation/train-data-maxlength16-subtitles.tsv'), header=False, index=False, sep='\\t')\n",
    "    valid_df.to_csv(os.path.join(os.getcwd(), 'data-preparation/valid-data-maxlength16-subtitles.tsv'), header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = pd.read_csv(os.path.join(os.getcwd(), 'data-preparation/train-data-maxlength16-subtitles.tsv'), sep='\\t', names=['sentence','class'])\n",
    "#tt['sentence'].iloc[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Vocabulary and Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('italian') + get_stop_words('english')\n",
    "\n",
    "my_stop_words = ['puoi','posso','vediamo','guarda','vorrei','voglio','dici','fammi']\n",
    "for my_word in my_stop_words:\n",
    "    stop_words.append(my_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criks', '16', '9']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = ['criks', 'crjis3','cr456is', '45crist','1v','f4','16','l','9','5ffff56566778','cv']\n",
    "\n",
    "falseIfDigit = lambda word: not bool((re.match('^(?=.*[0-9])', str(word))))\n",
    "\n",
    "[w for w in ww if (falseIfDigit(w) or w.isdigit()) and (len(w) > 2 or w.isdigit()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function returns FALSE if there is a digit in the string (i.e '4mmm', 'm44m', 'llp4')\n",
    "falseIfDigit = lambda word: not bool((re.match('^(?=.*[0-9])', str(word))))\n",
    "\n",
    "def get_vocab():\n",
    "    #allWords = []\n",
    "    vocab = set()\n",
    "    for text in train_df['sentence'].values:\n",
    "        words = text.split(' ')\n",
    "        # remove digits\n",
    "        words_only = [w for w in words if not w.isdigit()]\n",
    "        # exclude words shorter than 2, but not numbers. exclude words with numbers inside, i.e. '3cris', 'c45ris', 'cris23'\n",
    "        words_ = [w for w in words_only if (falseIfDigit(w) or w.isdigit()) and (len(w) > 2 or w.isdigit()) ]\n",
    "        #allWords = allWords + words_\n",
    "        word_set = set(words_)\n",
    "        vocab.update(word_set)\n",
    "    \n",
    "    #vocab.remove('')\n",
    "    return list(vocab)#, allWords\n",
    "\n",
    "def get_all_words():\n",
    "    allWords = []\n",
    "    cnt = 0\n",
    "    for text in train_df['sentence'].values:\n",
    "        words = text.split(' ')\n",
    "        # remove digits\n",
    "        words_only = [w for w in words if not w.isdigit()]\n",
    "        # exclude words shorter than 2, but not numbers. exclude words with numbers inside, i.e. '3cris', 'c45ris', 'cris23'\n",
    "        words_ = [w for w in words_only if (falseIfDigit(w) or w.isdigit()) and (len(w) > 2 or w.isdigit()) ]\n",
    "        allWords = allWords + words_\n",
    "        #word_set = set(words_)\n",
    "        cnt += 1\n",
    "        if cnt%10000==0:\n",
    "            print('-----------', cnt)\n",
    "    \n",
    "    return allWords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159180\n",
      "CPU times: user 7.09 s, sys: 11.9 ms, total: 7.1 s\n",
      "Wall time: 7.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = get_vocab()\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 10000\n",
      "----------- 20000\n",
      "----------- 30000\n",
      "----------- 40000\n",
      "----------- 50000\n",
      "----------- 60000\n",
      "----------- 70000\n",
      "----------- 80000\n",
      "----------- 90000\n",
      "----------- 100000\n",
      "----------- 110000\n",
      "----------- 120000\n",
      "----------- 130000\n",
      "----------- 140000\n",
      "----------- 150000\n",
      "----------- 160000\n",
      "----------- 170000\n",
      "----------- 180000\n",
      "----------- 190000\n",
      "----------- 200000\n",
      "----------- 210000\n",
      "----------- 220000\n",
      "----------- 230000\n",
      "----------- 240000\n",
      "----------- 250000\n",
      "----------- 260000\n",
      "----------- 270000\n",
      "----------- 280000\n",
      "----------- 290000\n",
      "----------- 300000\n",
      "----------- 310000\n",
      "CPU times: user 2h 27min 30s, sys: 1.45 s, total: 2h 27min 32s\n",
      "Wall time: 2h 27min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "allWords = get_all_words()\n",
    "len(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt_allWords = Counter(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_sorted_by_appearence = sorted(cnt_allWords.items(), key=lambda kv: len(vocab) - kv[1])\n",
    "#vocab_words_sorted_by_appearence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_sorted_by_appearence_list = [word[0] for word in vocab_words_sorted_by_appearence]\n",
    "#vocab_words_sorted_by_appearence_list, len(vocab_words_sorted_by_appearence_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158828\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS = True\n",
    "REDUCED_SIZE_VOC = True\n",
    "SIZE_VOC = 20000\n",
    "\n",
    "vocab = vocab_words_sorted_by_appearence_list\n",
    "\n",
    "if STOP_WORDS:\n",
    "    vocab = [w for w in vocab if w not in stop_words]\n",
    "    words_and_frequence = [ (word, freq) for (word, freq) in vocab_words_sorted_by_appearence if word not in stop_words]\n",
    "\n",
    "print(len(vocab))\n",
    "if REDUCED_SIZE_VOC:\n",
    "    vocab = vocab[0:SIZE_VOC]\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Mixed Vocabulary\n",
    "###### half of most frequent words, half of random selection among all the words (uniform distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['settimana',\n",
       " 'attivit√†',\n",
       " 'favore',\n",
       " 'piacere',\n",
       " 'appuntamento',\n",
       " 'calendario',\n",
       " 'prossimo',\n",
       " 'evento',\n",
       " 'condividere',\n",
       " 'nome']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From 0 to boundary_point: words selected by their frequency (the most frequent words)\n",
    "# From boundary_point to len(voc): words random selected\n",
    "boundary_point = 19000\n",
    "\n",
    "def random_selection_from_vocab(vocabulary, start):\n",
    "    length_voc = len(vocabulary)\n",
    "    vocab = np.array(vocabulary)\n",
    "    indxs = np.random.choice(range(start, length_voc), length_voc - start, replace=False)\n",
    "    return list(vocab[indxs])\n",
    "\n",
    "vocab = vocab[0:boundary_point] + random_selection_from_vocab(vocab, boundary_point)\n",
    "vocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_and_frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if a word is in VOC or STOP_WORDS\n",
    "ww = 'agenda'\n",
    "print(ww in stop_words)\n",
    "print(ww in vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_WORD = '#=KS=#'\n",
    "\n",
    "PATH_VOC = os.path.join(os.getcwd(), 'data-preparation/vocab_list_19k_1k_mystop_nodgts.tsv')\n",
    "with open(PATH_VOC , 'w') as file:\n",
    "#with open('/home/asr/Data/classif_task/jsgf_data/vocab_list.tsv', 'w') as file:\n",
    "    file.write(\"{}\\n\".format(PAD_WORD))\n",
    "    for word in vocab:\n",
    "        file.write(\"{}\\n\".format(word))\n",
    "        \n",
    "PATH_WORDS = os.path.join(os.getcwd(), 'data-preparation/n_words_19k_1k_mystop_nodgts.tsv')        \n",
    "with open(PATH_WORDS, 'w') as file:\n",
    "#with open('/home/asr/Data/classif_task/jsgf_data/n_words.tsv', 'w') as file:\n",
    "    file.write(str(len(vocab)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
